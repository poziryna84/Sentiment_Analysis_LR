{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comments_cosine_similarity_TF-IDF_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNcpO1p6CbUVK0H+663vMMq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poziryna84/Sentiment_Analysis_LR/blob/master/Comments_cosine_similarity_TF_IDF_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYmkg6-ko0F8",
        "outputId": "5ba74a6e-cd89-4c4a-cc90-093ad0013992"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGHnspaoMxB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a00aa14-8bd6-4377-9d2c-14eb62d9cf99"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords          \n",
        "from nltk.stem import PorterStemmer  \n",
        "from nltk.tokenize import TweetTokenizer \n",
        "import string\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1TpmFjqrfDq"
      },
      "source": [
        "# Loading and Viewing the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuGKaxrYMT9v"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/delectateam-nlptrainingexam-aa9ea86fa479/resources/vectorization/corpus.csv', header=None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-KF-z1oTvAq"
      },
      "source": [
        "data.columns = ['text']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsfAmECZaAcL",
        "outputId": "cf9fa920-2da8-4ea7-c25a-aa1224c010f9"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22998, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "vMrG6GS7M_j1",
        "outputId": "6afb9266-0907-4dfa-8ef9-079016e8365a"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I did not stay at the hotel but I was horribly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20 mins seated before I got a menu and I was t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The food was excellent but tthe service was te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Although the food was great the staff was awfu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fantastic pastry shop on La Via Rambla in Barc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  I did not stay at the hotel but I was horribly...\n",
              "1  20 mins seated before I got a menu and I was t...\n",
              "2  The food was excellent but tthe service was te...\n",
              "3  Although the food was great the staff was awfu...\n",
              "4  Fantastic pastry shop on La Via Rambla in Barc..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1HC0Gmzdvw7"
      },
      "source": [
        "# Functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiW8_ycWeXCw"
      },
      "source": [
        "def prepro_text(text):\n",
        "    '''\n",
        "    A function that does tokenizing, lowercasing, removing stop words and \n",
        "    punctuation and stems a string.\n",
        "    '''\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    stemmer = PorterStemmer() \n",
        "\n",
        "    # instantiate tokenizer class\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                                   reduce_len=True)\n",
        "\n",
        "    # tokenize tweets\n",
        "    string_tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    string_clean = []\n",
        "\n",
        "    # remove stop words and punctuation\n",
        "    for word in string_tokens:\n",
        "        if (word not in stopwords_english and\n",
        "            word not in string.punctuation):\n",
        "            string_clean.append(word)\n",
        "\n",
        "    # stemming the tokens\n",
        "    string_stem = []\n",
        "    for word in string_clean:\n",
        "        stem_word = stemmer.stem(word) \n",
        "        string_stem.append(stem_word) \n",
        "        \n",
        "    return string_stem\n",
        "\n",
        "def counter(list_of_toks):\n",
        "  dic = {}\n",
        "\n",
        "  for i in list_of_toks:\n",
        "    if i in dic:\n",
        "      dic[i] += 1\n",
        "    else:\n",
        "      dic[i] = 1\n",
        "  return dic\n",
        "\n",
        "  \n",
        "def tfScore(dic):\n",
        "  '''Function that converts dictionary of the term frequency per document into \n",
        "  tf score dictionary by dividing each count of a term in document by the total \n",
        "  number of terms in the document.\n",
        "  '''\n",
        "  num_words = sum(dic.values())\n",
        "  new_dic = {}\n",
        "  for k in dic:\n",
        "    new_dic[k] = dic[k]/ num_words\n",
        "    #new_dic[k] = 1 + np.log(dic[k]/ num_words)\n",
        "  \n",
        "  return new_dic\n",
        "\n",
        "def multValDict(d1, d2):\n",
        "  '''A function that multiplies the values of the correspondng keys of two \n",
        "  dictionaries.'''\n",
        "  d_new = {}\n",
        "  for k in d1:\n",
        "    d_new[k] = d1[k] * d2[k]\n",
        "  \n",
        "  return d_new\n",
        "\n",
        "def tfIdfExtract(lista):\n",
        "  #create a dictionary of unique terms as keys with the number of documents  \n",
        "  #where the term if found as their values\n",
        "  df = {}\n",
        "  #create an empty dictionary of the term frequency per document:\n",
        "  per_doc_freqs = {}\n",
        "  \n",
        "  for i in range(len(lista)):\n",
        "    #create d - document (set of pre-proccessed tokens)\n",
        "    d = prepro_text(lista[i])\n",
        "    \n",
        "    #add the index of the document as its key and its value as the dictionary of\n",
        "    #the words/tokens frequencies within the document to the term frequency per\n",
        "    #document dictionary\n",
        "    if len(counter(d)) > 0:\n",
        "      per_doc_freqs[i] = counter(d)\n",
        "\n",
        "    for tok in d:\n",
        "      if tok in df:\n",
        "        df[tok] += 1\n",
        "      else:\n",
        "        df[tok] = 1\n",
        "   \n",
        "  #create Tf dictionary by applying tfScore function\n",
        "  #to each key of the term frequency per document dictionary\n",
        "  tf = {}\n",
        "\n",
        "  for k in per_doc_freqs:\n",
        "    tf[k] = tfScore(per_doc_freqs[k])\n",
        "    \n",
        "  #create the number of unique terms across the corpus\n",
        "  N = len(df)\n",
        "\n",
        "  #create Inverse Document Frequency dictionary with its keys as unique terms\n",
        "  #and its values as their inverse document frequency score \n",
        "  # (Note that the idf formula above differs from the standard textbook\n",
        "  # notation that defines the idf as idf(t) = log [ n / (df(t) + 1) ])\n",
        "  idf_dict = {}\n",
        "  \n",
        "  for tok in df.keys():\n",
        "\n",
        "    # if df[tok] = 1:\n",
        "    idf = np.log(N / df[tok]) + 1\n",
        "    # if df[tok] = 2\n",
        "    #idf = np.log ((1 + N) / (1 + df[tok])) + 1\n",
        "    \n",
        "    idf_dict[tok] = idf\n",
        "\n",
        "  #create TfIdf dictionary by applying multValDict function to Tf and Idf \n",
        "  #dictionaries\n",
        "  tf_idf = {}\n",
        "  \n",
        "  for k in tf:\n",
        "    tf_idf[k] = multValDict(tf[k], idf_dict)\n",
        "\n",
        "  #create a zero matrix with the number of rows equal to the number of comments\n",
        "  #and the number of columns equal to the number of unique terms extracted in \n",
        "  #df. Fill the matrix with the value of the correspondig  key/term accessing \n",
        "  #the corresponding tf_idf dictionary key values\n",
        "\n",
        "  token_list = list(df.keys())\n",
        "  token_list.sort()\n",
        "  total_vocab_size = (len(token_list))\n",
        "\n",
        "  \n",
        "  row_num = len(lista)\n",
        "  \n",
        "  D = np.zeros((row_num, total_vocab_size))\n",
        "  for k in tf_idf:\n",
        "    for token in tf_idf[k]:\n",
        "      c = token_list.index(token)\n",
        "      D[k][c] = tf_idf[k][token]\n",
        "     \n",
        "  return D, token_list\n",
        "\n",
        "def cosSim(A, B):\n",
        "    '''\n",
        "    The function that takes in two vectors and computes the cosine distance\n",
        "    Input:\n",
        "        A: a numpy array which corresponds to a word vector\n",
        "        B: A numpy array which corresponds to a word vector\n",
        "    Output:\n",
        "        cos: numerical number representing the cosine similarity between A and B.\n",
        "    '''    \n",
        "    dot = np.dot(A,B)\n",
        "    norma = np.sqrt(sum(A**2))\n",
        "    normb = np.sqrt(sum(B**2)) \n",
        "    cos = dot/(norma*normb)\n",
        "    \n",
        "    return cos\n",
        "\n",
        "def simTex(com_index, sim_matrix, num_of_comments):\n",
        "  ''' Function that takes the df index of a (original) comment, similarity \n",
        "  matrix and the desired number of similar to the (original) comment comments \n",
        "  that the function will return.'''\n",
        "\n",
        "  v = sim_matrix[com_index]\n",
        "  v_sims = []\n",
        "  \n",
        "  for i in range(len(sim_matrix)):\n",
        "    v_sims.append(cosSim(sim_matrix[i],v))\n",
        "  df = pd.DataFrame(list(zip(data['text'], v_sims)))\n",
        "  df.columns = ['comments', 'scores']\n",
        "  df = df.sort_values(by=['scores'], ascending=False, ignore_index=True)\n",
        "  \n",
        "  print('The original comment: ')\n",
        "  print('                                                        ')\n",
        "  print(data.text[com_index])\n",
        "  print('********************************************************')\n",
        "  print(f'{num_of_comments} most similar coments and their corresponding scores:')\n",
        "  print('                                                        ')\n",
        "  df = df[1:num_of_comments]\n",
        "  \n",
        "  for i in df.index:\n",
        "    print(df['comments'][i], df['scores'][i])\n",
        "  \n",
        "  return"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W581yX59t1-f"
      },
      "source": [
        "# Creating TF-IDF matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urQ1d1ej8byO"
      },
      "source": [
        "m, l = tfIdfExtract(list(data['text']))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvWECZqruALb"
      },
      "source": [
        "# 10 most similar comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct4vTDavJY4Y",
        "outputId": "2562c8ef-1251-45a8-c9ab-397c408fec4a"
      },
      "source": [
        "simTex(0, m, 10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:152: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The original comment: \n",
            "                                                        \n",
            "I did not stay at the hotel but I was horribly treated in their restaurant.\n",
            "********************************************************\n",
            "10 most similar coments and their corresponding scores:\n",
            "                                                        \n",
            "HORRIBLE !! 0.6004833781355572\n",
            "Horrible service. 0.548315088475608\n",
            "horrible italian restaurant! 0.5122495625052131\n",
            "Treat yourself! 0.4927120274267418\n",
            "The place was recommended by the hotel we stayed at. 0.49000413602175535\n",
            "horrible night.... 0.4757284902759183\n",
            "It was not a horrible meal but also not as good as other restaurants in Barcelona. 0.4544513264976646\n",
            "This restaurant is a REAL treat! 0.4084227911612561\n",
            "Treat yourselves and go to this wonderful restaurant! 0.39377106419447483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wosSJIeGSqPh",
        "outputId": "8e512c05-93f4-4766-af22-c0e728248426"
      },
      "source": [
        "simTex(15342, m, 10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:152: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The original comment: \n",
            "                                                        \n",
            "However, the steak with pepper sauce is heavenly.\n",
            "********************************************************\n",
            "10 most similar coments and their corresponding scores:\n",
            "                                                        \n",
            "However, the steak with pepper sauce is heavenly. 1.0000000000000002\n",
            "sauce. 0.36587343139169975\n",
            "I had the pork loin with pepper sauce and it was very good. 0.3554825289747775\n",
            "All steaks come with three sauces. 0.35471100999714067\n",
            "I had the sirloin steak in pepper sauce which was excellent and the other three in our party had fish and chicken breast. 0.34908046878886395\n",
            "The bass (with lentils) was heavenly and the wines were delightful. 0.33319401374803576\n",
            "The second time i had grilled chicken in pepper sauce which was gorgeous. 0.32288787855546497\n",
            "Good steak (chuletón) and red peppers 0.32078359150125463\n",
            "My wife had Solomillo Cerdo Pimieta (steak in green pepper sauce). 0.3158305516860939\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}